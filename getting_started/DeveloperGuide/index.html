<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Developer Guide - LLMIR</title>
<meta name=description content="Large Language Model IR Compiler Framework"><meta name=generator content="Hugo 0.129.0"><link href=https://chenxingqiang.github.io/llmir-www/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://chenxingqiang.github.io/llmir-www/getting_started/DeveloperGuide/><link rel=stylesheet href=https://chenxingqiang.github.io/llmir-www/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://chenxingqiang.github.io/llmir-www/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://chenxingqiang.github.io/llmir-www/js/bundle.js></script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://chenxingqiang.github.io/llmir-www//mlir-logo.png width=40px align=absmiddle>
LLMIR</div></h1><span class=version>Version 0.0.1</span><p class=description>Large Language Model IR Compiler Framework</p></header><div class=global-menu><nav><ul><li><a href=/llmir-www/governance/>Governance</a></li><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/llmir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/llmir-www/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/llmir-www/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/chenxingqiang/llmir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/llmir-www/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/chenxingqiang/llmir>GitHub</a></li></ul></li><li><a href=https://github.com/chenxingqiang/llmir/issues>Bugs</a></li><li><a href=https://github.com/chenxingqiang/llmir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/LLMIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>Developer Guide</h1><h1 id=llmir-developer-guide>LLMIR Developer Guide</h1><p>This guide provides an overview of how to develop with LLMIR.</p><h2 id=building-llmir>Building LLMIR&nbsp;<a class=headline-hash href=#building-llmir>¶</a></h2><p>LLMIR is built on top of the MLIR ecosystem. To build LLMIR, you&rsquo;ll need:</p><ol><li>A C++ compiler (GCC or Clang) with C++17 support</li><li>CMake (3.13.4 or higher)</li><li>Python (3.7 or higher)</li><li>Ninja or Make build system</li></ol><h3 id=clone-the-repository>Clone the Repository&nbsp;<a class=headline-hash href=#clone-the-repository>¶</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/chenxingqiang/llmir.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> llmir
</span></span></code></pre></div><h3 id=configure-the-build>Configure the Build&nbsp;<a class=headline-hash href=#configure-the-build>¶</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir build <span class=o>&amp;&amp;</span> <span class=nb>cd</span> build
</span></span><span class=line><span class=cl>cmake -G Ninja ..
</span></span></code></pre></div><h3 id=build>Build&nbsp;<a class=headline-hash href=#build>¶</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ninja
</span></span></code></pre></div><h2 id=llmir-project-structure>LLMIR Project Structure&nbsp;<a class=headline-hash href=#llmir-project-structure>¶</a></h2><p>The LLMIR project is structured as follows:</p><pre tabindex=0><code>include/mlir/Dialect/LLM/       # MLIR dialect definitions
  ├── IR/                       # MLIR operations and types
  └── Runtime/                  # Runtime support headers

lib/Dialect/LLM/                # Implementation
  ├── IR/                       # MLIR operation implementations
  └── Runtime/                  # Runtime library implementations

test/Dialect/LLM/               # Tests
  ├── IR/                       # MLIR operation tests
  └── Runtime/                  # Runtime tests

examples/                       # Example applications
  └── kv_cache_example.cpp      # KV cache example
</code></pre><h2 id=core-components-under-development>Core Components (Under Development)&nbsp;<a class=headline-hash href=#core-components-under-development>¶</a></h2><p>LLMIR is being developed in phases according to our
<a href=https://github.com/chenxingqiang/llmir.git>development plan</a>. The core components are:</p><h3 id=phase-1-basic-infrastructure>Phase 1: Basic Infrastructure&nbsp;<a class=headline-hash href=#phase-1-basic-infrastructure>¶</a></h3><ul><li><strong>LLM MLIR Dialect</strong>: Specialized dialect defining operations and types for LLM inference</li><li><strong>Custom Type System</strong>: Types for representing KV caches, sharded tensors, etc.</li><li><strong>Core Operations</strong>: Attention, linear, layernorm, etc.</li></ul><h3 id=phase-2-core-optimizations>Phase 2: Core Optimizations&nbsp;<a class=headline-hash href=#phase-2-core-optimizations>¶</a></h3><ul><li><strong>KV Cache Management</strong>: PagedAttention-style block-based KV cache handling</li><li><strong>Attention Computation</strong>: Fusion and optimization of attention operations</li><li><strong>Memory Management</strong>: Block allocation and recycling strategies</li></ul><h3 id=phase-3-advanced-features>Phase 3: Advanced Features&nbsp;<a class=headline-hash href=#phase-3-advanced-features>¶</a></h3><ul><li><strong>Quantization Support</strong>: INT8/INT4 quantization transformations</li><li><strong>Parallelism Strategies</strong>: Tensor and pipeline parallelism</li><li><strong>Backend Code Generation</strong>: CUDA/CPU/accelerator support</li></ul><h2 id=contributing-to-llmir>Contributing to LLMIR&nbsp;<a class=headline-hash href=#contributing-to-llmir>¶</a></h2><p>LLMIR is in the early phases of development, and contributions are welcome. Here&rsquo;s how you can contribute:</p><ol><li>Review the development plan in our repository</li><li>Choose an area to focus on (dialect design, optimization, etc.)</li><li>Follow standard MLIR development practices</li><li>Submit pull requests with well-tested changes</li></ol><h2 id=development-workflow>Development Workflow&nbsp;<a class=headline-hash href=#development-workflow>¶</a></h2><p>We recommend the following workflow for contributing to LLMIR:</p><ol><li>Create a new branch for your feature</li><li>Implement the necessary changes with appropriate tests</li><li>Update documentation to reflect your changes</li><li>Submit a pull request for review</li></ol><h2 id=running-tests>Running Tests&nbsp;<a class=headline-hash href=#running-tests>¶</a></h2><p>Once tests are implemented, you can run them from the build directory:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ninja check-llmir
</span></span></code></pre></div><h2 id=example-kv-cache-in-mlir>Example: KV Cache in MLIR&nbsp;<a class=headline-hash href=#example-kv-cache-in-mlir>¶</a></h2><p>Here&rsquo;s an example of how a paged KV cache might be represented in LLMIR (syntax may evolve as the project develops):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Create a paged KV cache type
</span></span></span><span class=line><span class=cl><span class=c></span><span class=p>!</span><span class=nl>kv_cache_t =</span> <span class=p>!</span>llm<span class=p>.</span>paged_kv_cache<span class=p>&lt;</span><span class=k>f16</span><span class=p>,</span> <span class=m>12</span><span class=p>,</span> <span class=m>16</span><span class=p>,</span> <span class=m>64</span><span class=p>,</span> <span class=m>16</span><span class=p>,</span> <span class=m>4096</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Append key-value pairs to the cache
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%new_kv</span><span class=p>,</span> <span class=nv>%block_indices</span> <span class=p>=</span> llm<span class=p>.</span>append_kv <span class=nv>%kv_cache</span><span class=p>,</span> <span class=nv>%keys</span><span class=p>,</span> <span class=nv>%values</span><span class=p>,</span> <span class=nv>%seq_ids</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nl>block_size =</span> <span class=m>16</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nl>max_seq_len =</span> <span class=m>4096</span> <span class=p>:</span> <span class=k>i32</span>
</span></span><span class=line><span class=cl><span class=p>}</span> <span class=p>:</span> <span class=p>(!</span>kv_cache_t<span class=p>,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x1x16x64x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x1x16x64x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;)</span> 
</span></span><span class=line><span class=cl>    <span class=p>-&gt;</span> <span class=p>(!</span>kv_cache_t<span class=p>,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>i32</span><span class=p>&gt;)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Perform paged attention with the KV cache
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%output</span> <span class=p>=</span> llm<span class=p>.</span>paged_attention <span class=nv>%query</span><span class=p>,</span> <span class=nv>%new_kv</span><span class=p>,</span> <span class=nv>%block_indices</span><span class=p>,</span> <span class=nv>%seq_lens</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nl>num_heads =</span> <span class=m>16</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nl>head_dim =</span> <span class=m>64</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nl>scale =</span> <span class=m>0.125</span> <span class=p>:</span> <span class=k>f32</span>
</span></span><span class=line><span class=cl><span class=p>}</span> <span class=p>:</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x1x16x64x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=p>!</span>kv_cache_t<span class=p>,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x128x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;)</span> 
</span></span><span class=line><span class=cl>    <span class=p>-&gt;</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>2x1x16x64x</span><span class=k>f16</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>For more details on the project roadmap and architecture, please refer to our
<a href=https://github.com/chenxingqiang/llmir.git>GitHub repository</a>.</p><div class=edit-meta><br><a href=https://github.com/chenxingqiang/llmir-www//edit/main/docs/content/ class=edit-page><i class="fas fa-pen-square"></i> Edit on GitHub</a></div><nav class=pagination><a class="nav nav-prev" href=https://chenxingqiang.github.io/llmir-www/getting_started/TestingGuide/ title="Testing Guide"><i class="fas fa-arrow-left" aria-hidden=true></i> Prev - Testing Guide</a>
<a class="nav nav-next" href=https://chenxingqiang.github.io/llmir-www/getting_started/Faq/ title=FAQ>Next - FAQ <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://chenxingqiang.github.io/llmir-www/>Home</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/governance/>Governance</a></li><li class=has-sub-menu><a href=https://chenxingqiang.github.io/llmir-www/docs/>Documentation<span class="mark closed">+</span></a><ul class=sub-menu><li class=has-sub-menu><a href=https://chenxingqiang.github.io/llmir-www/docs/architecture/>Architecture<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://chenxingqiang.github.io/llmir-www/docs/architecture/KVCache/>KV Cache Optimization</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/docs/architecture/Quantization/>Quantization Support</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/docs/architecture/DistributedDeployment/>Distributed Deployment</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/docs/architecture/PerformanceEvaluation/>Performance Evaluation</a></li></ul></li><li><a href=https://chenxingqiang.github.io/llmir-www/docs/References/>References</a></li></ul></li><li><a href=https://chenxingqiang.github.io/llmir-www/pubs/>LLMIR Related Publications</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/users/>Users of MLIR</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/deprecation/>Deprecations & Current Refactoring</a></li><li class="parent has-sub-menu"><a href=https://chenxingqiang.github.io/llmir-www/getting_started/>Getting Started<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://chenxingqiang.github.io/llmir-www/getting_started/Faq/>FAQ</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/getting_started/ReportingIssues/>Reporting Issues</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/getting_started/Debugging/>Debugging Tips</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/getting_started/Contributing/>How to Contribute</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/getting_started/openprojects/>Open Projects</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/getting_started/Glossary/>Glossary</a></li><li><a href=https://chenxingqiang.github.io/llmir-www/getting_started/TestingGuide/>Testing Guide</a></li><li class=active><a href=https://chenxingqiang.github.io/llmir-www/getting_started/DeveloperGuide/>Developer Guide</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>